{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e886fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import feedparser\n",
    "#force Python to skip SSL certificate verification for HTTPS connections\n",
    "import ssl\n",
    "if hasattr(ssl, '_create_unverified_context'):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a646bc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'Article Title': 'Trump Says US Will Be ‘Very Rich’ as Tariffs Go Into Effect',\n",
       "  'Article Link': 'https://www.today.com/video/trump-s-broad-tariffs-take-effect-against-nearly-100-countries-244505157738',\n",
       "  'Date and Time Published': 'Thu, 07 Aug 2025 11:24:04 GMT'},\n",
       " 2: {'Article Title': 'Trump demands resignation of Intel CEO over alleged China ties',\n",
       "  'Article Link': 'https://www.nbcnews.com/business/business-news/trump-demands-intel-ceo-resign-rcna223594',\n",
       "  'Date and Time Published': 'Thu, 07 Aug 2025 13:11:17 GMT'},\n",
       " 3: {'Article Title': \"India's Modi says he is ready to 'pay a big price' in the face of U.S. tariffs\",\n",
       "  'Article Link': 'https://www.nbcnews.com/politics/trump-administration/live-blog/trump-tariffs-putin-ukraine-redistricting-immigration-live-updates-rcna222780/rcrd85997?canonicalCard=true',\n",
       "  'Date and Time Published': 'Thu, 07 Aug 2025 15:05:43 GMT'},\n",
       " 4: {'Article Title': 'Trump and Putin Set to Meet ‘in Coming Days’',\n",
       "  'Article Link': 'https://www.today.com/video/donald-trump-and-vladimir-putin-set-to-meet-in-coming-days-244505669938',\n",
       "  'Date and Time Published': 'Thu, 07 Aug 2025 11:18:59 GMT'},\n",
       " 5: {'Article Title': 'Trump demands resignation of Intel CEO over alleged China ties',\n",
       "  'Article Link': 'https://www.nbcnews.com/business/business-news/trump-demands-intel-ceo-resign-rcna223594',\n",
       "  'Date and Time Published': 'Thu, 07 Aug 2025 13:11:17 GMT'},\n",
       " 6: {'Article Title': \"Kremlin says Putin-Trump meeting will happen in 'coming days'\",\n",
       "  'Article Link': 'https://www.nbcnews.com/world/russia/russia-putin-trump-meeting-confirmed-ukraine-rcna223572',\n",
       "  'Date and Time Published': 'Thu, 07 Aug 2025 08:42:19 GMT'},\n",
       " 7: {'Article Title': 'Family of victim and survivors of Indianapolis FedEx mass shooting file lawsuit against gun magazine manufacturer and distributors',\n",
       "  'Article Link': 'https://www.cnn.com/2023/04/16/us/lawsuit-indianapolis-fedex-mass-shooting/index.html',\n",
       "  'Date and Time Published': 'Mon, 17 Apr 2023 18:54:28 GMT'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "function takes a list of websites as input and looks at all useful key value pairs for all news articles on all websites provided\n",
    "useful keys are:\n",
    "'title', 'summary', 'content' as these are the most likely locations to find the key words related to accidents\n",
    "'link' to output the direct access to the article that is found to be related to an accident\n",
    "'published' to make sure the date of the article is current/output the date to the user\n",
    "function outputs \"articles\" (a list of dictionaries where each dictionary contains the relevant information for one article)\n",
    "'''\n",
    "def extract_articles(websites: list):\n",
    "    articles = [] #list with information of all articles\n",
    "    for website in websites:\n",
    "        feed = feedparser.parse(website) #feed rss data in\n",
    "        for entry in feed.entries:\n",
    "            article_data = {} #dict for current article\n",
    "\n",
    "            for key in (\"title\", \"summary\", \"link\", \"published\"): #loop through the important keys and add these key/value pairs to our current article dict\n",
    "                if key in entry:\n",
    "                    article_data[key] = entry[key]\n",
    "\n",
    "            if \"content\" in entry and isinstance(entry[\"content\"], list): #make sure content key/value info is available for this article and that its a list. also make sure content has \"value\" inside since thats where the content informaiton is in the content\n",
    "                content_item = entry[\"content\"][0]\n",
    "                if \"value\" in content_item:\n",
    "                    article_data[\"content\"] = content_item[\"value\"]\n",
    "\n",
    "            articles.append(article_data)\n",
    "    \n",
    "    return articles\n",
    "    \n",
    "\n",
    "'''\n",
    "function takes \"articles\" (list of dictionaries where each dictionary contains the relevant information for one article) and \"keywords\" (list of keywords we want to find articles about) as input\n",
    "outputs \"relevant_articles\" list of articles that contain at least one of the provided keywords\n",
    "'''\n",
    "def get_relevant_articles(articles: list, keywords: list):   \n",
    "    relevant_articles = {}\n",
    "    count = 1\n",
    "    for article in articles:\n",
    "        for key, value in article.items(): #for each key value pair for each article, we confirm that the value is a string and then check if any of the keywords are in the value\n",
    "            if isinstance(value, str) and any(keyword.lower() in value.lower() for keyword in keywords):#if it is we take the article title, link, and publish time and put it in the dict relevant_articles which is the output\n",
    "                title = article.get('title')\n",
    "                link = article.get('link')\n",
    "                published = article.get('published')\n",
    "                relevant_articles[count] = {'Article Title': title, 'Article Link': link, 'Date and Time Published': published}\n",
    "                count +=1\n",
    "                break\n",
    "            \n",
    "    return relevant_articles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "get_relevant_articles(extract_articles(['https://feeds.nbcnews.com/nbcnews/public/news',\"http://rss.cnn.com/rss/cnn_us.rss\"]), [\"trump\", \"fedex\"])\n",
    "\n",
    "\n",
    "# # Use this code to see all of the articles\n",
    "# def view_all(website: str):\n",
    "#     article_dictionary = feedparser.parse(website) #load in rss news feed site and put all information in dict\n",
    "#     for i in article_dictionary.entries:\n",
    "#         print(\"\\n--------------\")\n",
    "#         for key, value in i.items():\n",
    "#             print(f\"{key}: {value}\")\n",
    "\n",
    "# view_all('http://rss.cnn.com/rss/cnn_us.rss')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.set_page_config(page_title=\"Incident Feed\", layout=\"wide\") #set title that is shown in browser tab\n",
    "\n",
    "st.title(\"Lab & Environmental Emergency News Monitor\") #set title shown at top of webpage\n",
    "\n",
    "with st.sidebar: #sidebar\n",
    "    st.header(\"User Inputs:\") #header for the sidebar\n",
    "    \n",
    "    rss_input = st.text_area(\"RSS Feed URLs (one per line)\",  #creates a field for the web feed url inputs with a couple links put in by default for the user \n",
    "        value=\"\"\"https://feeds.nbcnews.com/nbcnews/public/news\n",
    "http://rss.cnn.com/rss/cnn_us.rss\"\"\")\n",
    "    \n",
    "    keyword_input = st.text_input(\"Desired Keywords (comma-separated)\", value=\"lab, fire, explosion, chemical, environmental\") #creates a field for the user to input keywords, with a list of default words\n",
    "\n",
    "    run_search = st.button(\"Run News Scan\") #creates a button with text telling the user what the button does\n",
    "\n",
    "if run_search: #if the user clicks the button\n",
    "    rss_feeds = [url.strip() for url in rss_input.strip().splitlines() if url.strip()] #we want to take all the text in the rss_feeds input box, and process them into a list of URLs\n",
    "    keywords = [kw.strip().lower() for kw in keyword_input.split(\",\") if kw.strip()] #take all the text in keyword_input input box, split them by comma, if keyword.strip is not empty, append the lowercased keyword\n",
    "    \n",
    "    with st.spinner(\"Scanning feeds for relevant articles...\"): # when user hits run button give this loading text\n",
    "        articles = extract_articles(rss_feeds) #then run the two functions to get the relevant articles\n",
    "        filtered_articles = get_relevant_articles(articles, keywords)\n",
    "\n",
    "    st.subheader(f\"Found {len(filtered_articles)} relevant articles!\") #once the above has run, we output the text with the number of articles found\n",
    "\n",
    "    for counter, article in filtered_articles.items(): #loop through the filtered_articles dictionary from our function\n",
    "        st.markdown(f\"### {counter}. {article['Article Title']}\") #output the counter number (key) and the portion of the value that contains each info we want\n",
    "        st.markdown(f\"**Published:** {article['Date and Time Published']}\")\n",
    "        st.markdown(f\"[Read Article]({article['Article Link']})\") #create a hyperlink, user sees the text inside [] and text in () is the link\n",
    "        st.markdown(\"---\") #divider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_articles(articles: list, keywords: list):\n",
    "    relevant_articles = {}\n",
    "    count = 1\n",
    "\n",
    "    keyword_patterns = {\n",
    "        keyword: re.compile(rf'\\b{re.escape(keyword)}\\b', re.IGNORECASE)\n",
    "        for keyword in keywords\n",
    "    }\n",
    "\n",
    "    for article in articles:\n",
    "        matched_keywords = set()\n",
    "\n",
    "        for key, value in article.items():\n",
    "            if isinstance(value, str):\n",
    "                for keyword, pattern in keyword_patterns.items():\n",
    "                    if pattern.search(value):\n",
    "                        matched_keywords.add(keyword)\n",
    "\n",
    "        if matched_keywords:\n",
    "            relevant_articles[count] = {\n",
    "                'Article Title': article.get('title'),\n",
    "                'Article Link': article.get('link'),\n",
    "                'Date and Time Published': article.get('published'),\n",
    "                'Matched Keywords': sorted(matched_keywords)  # sorted for consistency\n",
    "            }\n",
    "            count += 1\n",
    "\n",
    "    return relevant_articles\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_social_listening",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
